# Implementation Roadmap: Quote/Trade Data Consolidation

## Overview
This document outlines the concrete steps needed to implement a comprehensive quote/trade data collection and aggregation system. Based on our research findings, we'll implement a minute-level aggregation strategy that enhances our current system with buy/sell pressure analysis.

## Current System State

### âœ… What We Have
- **Minute aggregates (XA)** working with basic OHLC + volume
- **SQLite database** with market_data table
- **Real-time dashboard** with price/volume charts
- **Anomaly detection** for volume spikes
- **WebSocket connection** to crypto trades (XT) and quotes (XQ)

### ğŸ¯ What We Need
- **Buy/sell pressure indicators** from trade conditions
- **Order flow analysis** from trade direction
- **Liquidity metrics** from spread analysis  
- **Enhanced aggregation** combining quotes + trades
- **Database schema** for microstructure data

## Implementation Phases

### Phase 1: Database Schema Enhancement (1-2 hours)
**Goal**: Extend current database to store buy/sell pressure data

#### Tasks:
1. **Update database schema**
   ```sql
   ALTER TABLE market_data ADD COLUMN buy_volume REAL DEFAULT 0;
   ALTER TABLE market_data ADD COLUMN sell_volume REAL DEFAULT 0;
   ALTER TABLE market_data ADD COLUMN buy_trade_count INTEGER DEFAULT 0;
   ALTER TABLE market_data ADD COLUMN sell_trade_count INTEGER DEFAULT 0;
   ALTER TABLE market_data ADD COLUMN avg_spread REAL DEFAULT 0;
   ALTER TABLE market_data ADD COLUMN quote_updates INTEGER DEFAULT 0;
   ```

2. **Update database.py functions**
   - Modify `store_market_data()` to handle new fields
   - Add validation for buy/sell volume consistency
   - Update database initialization

3. **Migrate existing data**
   - Add default values for new columns
   - Verify data integrity

#### Success Criteria:
- [ ] Database schema updated successfully
- [ ] Existing data preserved
- [ ] New fields accessible in dashboard queries

### Phase 2: Microstructure Data Collection (2-3 hours)
**Goal**: Build system to collect and process XT (trades) and XQ (quotes) data

#### Tasks:
1. **Create microstructure collector** (`src/data/collect_microstructure.py`)
   ```python
   class CryptoMicrostructureCollector:
       def __init__(self):
           self.trade_buffer = {}  # Current minute trades
           self.quote_buffer = {}  # Current minute quotes
           
       def on_trade(self, trade_data):
           # Process XT messages
           pass
           
       def on_quote(self, quote_data):
           # Process XQ messages  
           pass
           
       def aggregate_minute(self, symbol, timestamp):
           # Combine trades + quotes into minute summary
           pass
   ```

2. **Implement trade condition analysis**
   ```python
   def analyze_trade_direction(trade):
       conditions = trade.get('c', [])
       if 1 in conditions:
           return 'buy'  # Market buy (hit ask)
       elif 2 in conditions:
           return 'sell'  # Market sell (hit bid)
       else:
           return 'unknown'
   ```

3. **Build quote spread analysis**
   ```python
   def analyze_quote_data(quotes_list):
       spreads = [q['ask'] - q['bid'] for q in quotes_list]
       return {
           'avg_spread': mean(spreads),
           'min_spread': min(spreads),  
           'max_spread': max(spreads),
           'quote_updates': len(quotes_list)
       }
   ```

4. **Update WebSocket handlers**
   - Route XT messages to trade processor
   - Route XQ messages to quote processor  
   - Maintain backward compatibility with XA

#### Success Criteria:
- [ ] XT (trade) messages processed correctly
- [ ] XQ (quote) messages processed correctly
- [ ] Trade conditions [1]/[2] identified as buy/sell
- [ ] Spread calculations working
- [ ] Minute aggregation producing enhanced data

### Phase 3: Dashboard Integration (1-2 hours)
**Goal**: Add buy/sell pressure visualization to existing charts

#### Tasks:
1. **Enhance combined charts** in `monitoring/dashboard.py`
   ```python
   def create_buysell_pressure_chart(df, symbol):
       # Add buy/sell volume bars with different colors
       # Green bars for net buying, red bars for net selling
       # Include buy/sell ratio indicator
   ```

2. **Add new dashboard sections**
   - **Order Flow Analysis**: Buy vs sell volume over time
   - **Spread Analysis**: Average spread and liquidity indicators
   - **Trade Count Analysis**: Buy vs sell initiated trades

3. **Update chart tooltips**
   - Show buy/sell breakdown on hover
   - Display spread information
   - Include trade count details

4. **Add buy/sell pressure indicators**
   ```python
   buy_sell_ratio = buy_volume / (sell_volume + 0.0001)  # Avoid div by zero
   pressure_indicator = "ğŸŸ¢ BUY" if buy_sell_ratio > 1.2 else "ğŸ”´ SELL" if buy_sell_ratio < 0.8 else "âšª NEUTRAL"
   ```

#### Success Criteria:
- [ ] Charts show buy/sell volume breakdown
- [ ] Buy/sell pressure indicators visible
- [ ] Spread analysis displayed
- [ ] Real-time updates working

### Phase 4: Advanced Analysis (2-3 hours)
**Goal**: Implement sophisticated buy/sell pressure analytics

#### Tasks:
1. **Order flow imbalance calculation**
   ```python
   def calculate_order_flow_imbalance(trades):
       buy_volume = sum(t['size'] for t in trades if t['direction'] == 'buy')
       sell_volume = sum(t['size'] for t in trades if t['direction'] == 'sell')
       total_volume = buy_volume + sell_volume
       return (buy_volume - sell_volume) / total_volume if total_volume > 0 else 0
   ```

2. **Liquidity analysis**
   ```python
   def analyze_liquidity(quotes, trades):
       avg_spread = mean(q['spread'] for q in quotes)
       spread_stability = 1 - (std_dev(spreads) / mean(spreads))
       price_impact = calculate_price_impact(trades)
       return {
           'liquidity_score': combine_metrics(avg_spread, spread_stability, price_impact),
           'spread_stability': spread_stability,
           'avg_spread': avg_spread
       }
   ```

3. **Enhanced anomaly detection**
   ```python
   def detect_order_flow_anomalies(current_data, historical_baseline):
       # Detect unusual buy/sell imbalances
       # Identify liquidity drops (spread spikes)
       # Flag large trade size anomalies
       pass
   ```

4. **Real-time alerts system**
   - Buy/sell pressure divergence alerts
   - Liquidity crisis warnings (spread > threshold)
   - Large trade impact notifications

#### Success Criteria:
- [ ] Order flow imbalance calculations working
- [ ] Liquidity metrics displaying correctly
- [ ] Enhanced anomaly detection running
- [ ] Real-time alerts functional

## Technical Implementation Details

### Data Structures

#### Enhanced Market Data Record
```python
{
    "timestamp": "2025-09-23T19:15:00.000Z",
    "symbol": "BTC-USD",
    "price": 112244.39,      # Close price (existing)
    "volume": 0.0847,        # Total volume (existing)
    "high": 112260.85,       # High price (existing)  
    "low": 112235.50,        # Low price (existing)
    "open": 112240.00,       # Open price (existing)
    "vwap": 112248.12,       # VWAP (existing)
    
    # New fields
    "buy_volume": 0.0521,         # Volume from condition [1] trades
    "sell_volume": 0.0326,        # Volume from condition [2] trades  
    "buy_trade_count": 54,        # Number of buy trades
    "sell_trade_count": 35,       # Number of sell trades
    "avg_spread": 1.85,           # Average bid-ask spread
    "quote_updates": 342          # Number of quote updates
}
```

#### Processing Buffers
```python
class MinuteBuffer:
    def __init__(self, timestamp, symbol):
        self.timestamp = timestamp
        self.symbol = symbol
        self.trades = []      # XT messages
        self.quotes = []      # XQ messages  
        self.aggregates = []  # XA messages (backup)
        
    def add_trade(self, trade_data):
        self.trades.append({
            'timestamp': trade_data['t'],
            'price': trade_data['p'],
            'size': trade_data['s'], 
            'conditions': trade_data['c'],
            'direction': self.analyze_direction(trade_data['c'])
        })
        
    def add_quote(self, quote_data):
        self.quotes.append({
            'timestamp': quote_data['t'],
            'bid': quote_data['bp'],
            'ask': quote_data['ap'],
            'spread': quote_data['ap'] - quote_data['bp']
        })
```

### Performance Considerations

#### Memory Management
- **Rolling buffers** for current minute data
- **Batch processing** every minute boundary
- **Memory cleanup** after aggregation

#### Database Optimization  
- **Batch inserts** for multiple symbols
- **Index optimization** for time-series queries
- **Connection pooling** for concurrent access

#### Real-time Processing
- **Async message handling** to prevent blocking
- **Queue management** for high-frequency data
- **Error resilience** for network interruptions

## Testing Strategy

### Unit Tests
1. **Trade direction analysis** accuracy
2. **Spread calculation** correctness  
3. **Minute aggregation** logic
4. **Database operations** integrity

### Integration Tests  
1. **End-to-end data flow** (WebSocket â†’ Database)
2. **Dashboard updates** with new data
3. **Real-time processing** under load
4. **Data consistency** across restarts

### Validation Tests
1. **Buy/sell ratios** vs known market movements
2. **Spread analysis** vs market volatility
3. **Liquidity indicators** correlation checks
4. **Anomaly detection** precision/recall

## Timeline & Milestones

### Week 1: Foundation
- **Day 1-2**: Database schema enhancement
- **Day 3-4**: Basic microstructure collection
- **Day 5**: Dashboard integration basics

### Week 2: Enhancement  
- **Day 1-2**: Advanced analytics implementation
- **Day 3-4**: Testing and optimization
- **Day 5**: Documentation and refinement

### Success Metrics
- [ ] **Data collection**: >99% message capture rate
- [ ] **Processing speed**: <100ms aggregation latency  
- [ ] **Dashboard responsiveness**: <2s update time
- [ ] **Analysis accuracy**: Buy/sell signals correlate with price movements

## Risk Mitigation

### Technical Risks
- **High data volume**: Implement efficient buffering and batch processing
- **WebSocket reliability**: Add reconnection logic and message recovery
- **Database performance**: Use indexes and connection pooling
- **Memory usage**: Implement cleanup and monitoring

### Analysis Risks  
- **Condition code interpretation**: Research Polygon.io documentation thoroughly
- **Market regime changes**: Monitor and adjust thresholds dynamically  
- **False signals**: Validate indicators against known market events
- **Latency effects**: Account for processing delays in real-time analysis

## Conclusion

This roadmap provides a systematic approach to implementing comprehensive crypto market microstructure analysis. By following these phases, we'll build a robust system that enhances our current anomaly detection with sophisticated buy/sell pressure indicators and liquidity analytics.

The implementation balances complexity with practicality, starting with proven minute-level aggregation and building towards advanced order flow analysis. Each phase delivers value while preparing for the next level of sophistication.

---

*Implementation Roadmap - Created September 23, 2025*