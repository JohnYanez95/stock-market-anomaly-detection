# Stock Market Anomaly Detection Pipeline

Real-time anomaly detection system for stock market data with production-grade MLOps infrastructure.

## Project Overview

This project implements a complete anomaly detection pipeline for stock market data, featuring:

- Real-time data ingestion from Polygon.io API
- Feature store implementation with Feast
- ML models: Isolation Forest and LSTM Autoencoder
- MLflow for experiment tracking and model registry
- FastAPI serving with Redis caching
- SHAP-based interpretability
- Real-time monitoring dashboard

## Tech Stack

- **Data Source**: Polygon.io API (WebSocket + REST)
- **Feature Store**: Feast
- **ML Framework**: scikit-learn, TensorFlow/Keras
- **MLOps**: MLflow
- **API**: FastAPI
- **Caching**: Redis
- **Monitoring**: Streamlit
- **Interpretability**: SHAP

## Project Structure

```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/          # Raw market data
â”‚   â”œâ”€â”€ processed/    # Cleaned and preprocessed data
â”‚   â””â”€â”€ features/     # Feature store data
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/         # Data ingestion and processing
â”‚   â”œâ”€â”€ features/     # Feature engineering
â”‚   â”œâ”€â”€ models/       # ML models and training
â”‚   â””â”€â”€ api/          # FastAPI application
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ exploration/  # Data exploration and analysis
â”œâ”€â”€ configs/          # Configuration files
â”œâ”€â”€ tests/           # Unit and integration tests
â”œâ”€â”€ deployment/      # Docker and Kubernetes configs
â”‚   â”œâ”€â”€ docker/
â”‚   â””â”€â”€ kubernetes/
â”œâ”€â”€ monitoring/      # Monitoring and alerting
â””â”€â”€ docs/           # Documentation
```

## Getting Started

### Prerequisites

- **Python 3.10+** (tested with 3.10.12)
- **Polygon.io API key** (free tier: 10,000 calls/month)
- **Git** for version control
- Redis server (for future caching implementation)
- Docker (optional, for containerized deployment)

### Installation

1. Clone the repository:
```bash
git clone https://github.com/JohnYanez95/stock-market-anomaly-detection.git
cd stock-market-anomaly-detection
```

2. Create virtual environment and install dependencies:
```bash
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt

# Install MLOps packages separately (due to dependency conflicts)
pip install mlflow feast
```

3. Set up environment variables:
```bash
cp .env.example .env
# Edit .env with your Polygon.io API key
```

### Quick Start

1. **Data Collection**:
```bash
# Activate virtual environment
source venv/bin/activate

# Collect sample data (AAPL, GOOGL, MSFT, TSLA, VOO)
python src/data/collect_data.py
```

2. **Feature Engineering**:
```bash
python src/features/build_features.py
```

3. **Model Training**:
```bash
python src/models/train_model.py
```

4. **Start API Server**:
```bash
uvicorn src.api.main:app --reload
```

5. **Launch Dashboard**:
```bash
streamlit run monitoring/dashboard.py
```

## Current Status

**âœ… Completed (Week 1)**
- Environment setup with Python 3.10 virtual environment
- All dependencies installed (TensorFlow, scikit-learn, FastAPI, MLflow, Feast)
- Polygon.io API integration working
- Historical data collection implemented
- Sample dataset collected: 5 symbols, ~19,000 total records
- Data schema identified: OHLC prices, volume, VWAP, transaction counts

**ðŸ“Š Available Data**
- **AAPL**: 3,762 minute-level records (Sep 11-17, 2025)
- **GOOGL**: 3,522 records
- **MSFT**: 3,120 records  
- **TSLA**: 4,700 records (highest volume)
- **VOO**: 2,574 records (ETF, lower frequency)

**ðŸš§ Next Steps**
- Real-time WebSocket data streaming
- Feature engineering pipeline
- Anomaly detection model development

## Development Roadmap

### Week 1-2: Data Pipeline Foundation
- [x] Project setup and structure
- [x] Environment setup with virtual environment
- [x] Dependencies installed (ML, MLOps, API frameworks)
- [x] Polygon.io API integration
- [x] Historical data collection for AAPL, GOOGL, MSFT, TSLA, VOO
- [x] Data schema exploration (OHLC, volume, VWAP, transactions)
- [ ] WebSocket real-time connection
- [ ] Basic feature engineering

### Week 3-4: ML Pipeline
- [ ] Feast feature store setup
- [ ] Isolation Forest implementation
- [ ] LSTM Autoencoder development
- [ ] Backtesting framework

### Week 5-6: Production Systems
- [ ] MLflow experiment tracking
- [ ] Model registry and promotion
- [ ] FastAPI endpoint development
- [ ] Real-time dashboard

### Week 7-8: Polish & Interpretability
- [ ] SHAP implementation
- [ ] Historical validation
- [ ] Performance optimization
- [ ] Documentation and blog post

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## License

MIT License - see LICENSE file for details

## Contact

For questions or suggestions, please open an issue.